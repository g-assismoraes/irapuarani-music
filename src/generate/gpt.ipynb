{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '..\\..\\data\\\\txt-from-midi'\n",
    "output_path = '..\\..\\data\\\\generations\\\\gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(music):\n",
    "        return  f'''You will classify music represented in symbolic form as either positive or negative.\n",
    "\n",
    "### Symbolic Representation\n",
    "d_[duration]_[dots]: Defines the duration of the upcoming notes. The [duration] specifies the type of note (e.g., breve, whole, half, quarter, eighth, 16th, or 32nd). The [dots] indicates the number of dots extending the noteâ€™s duration, and can be any integer from 0 to 3.\n",
    "v_[velocity]: Indicates the velocity (or loudness) of the following notes. Velocity is discretized into bins of size 4, allowing values such as 4, 8, 12, up to 128.\n",
    "t_[tempo]: Changes the tempo of the piece, measured in beats per minute (bpm). Tempo is discretized into bins of size 4, ranging from 24 to 160 bpm. This controls the speed at which the piece is played.\n",
    "w_[wait]: Specifies the number of time steps (units of waiting) that pass before the next musical event occurs. The value associated with w, such as in w_2 or w_3, represents the number of time steps with no musical events.\n",
    "\\n: Marks the end of the piece.\n",
    "\n",
    "### Music\n",
    "{music}\n",
    "\n",
    "\n",
    "Your answer must strictly follow this format:\n",
    "- answer: A string, either \"positive\" or \"negative\"\n",
    "- justify: A brief explanation justifying your classification\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for filename in os.listdir(input_path):\n",
    "    if filename.endswith('.txt'):  \n",
    "        file_path = os.path.join(input_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        data.append({'file_name': filename, 'content': content})\n",
    "    \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    max_completion_tokens=500\n",
    "    )\n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    file_name = row['file_name']\n",
    "    music_content = row['content'][:1800] \n",
    "    \n",
    "    \n",
    "    response = get_response(get_prompt(music_content))\n",
    "    generated_texts = response.content\n",
    "    \n",
    "    result = {\n",
    "        \"file_name\": file_name,\n",
    "        \"music_passed_to_model\": music_content,\n",
    "        \"model_output\": generated_texts\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_name = 'gpt-4o-mini'\n",
    "    if '/' in output_name:\n",
    "        output_name = output_name.split('/')[-1]\n",
    "        \n",
    "    json_output_path = os.path.join(output_path, f\"{output_name}_temp1.json\")\n",
    "    with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
